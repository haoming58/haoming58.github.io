---
layout: note_with_toc
title: 3. 编码注意力机制
description: Understanding attention mechanisms in transformers and self-attention
category: LLM
subcategory: Attention
tags: [LLM, Attention, Self-Attention, Transformer, Deep Learning]
permalink: /notes/attention-mechanism/
---

# 3 编码注意力机制

## 3.1 理解注意力机制

起源是语言翻译时，不能简单地逐词翻译。编码器和解码器。编码器的任务是首先读取和处理整个文本，然后解码器生成翻译后的文本。

最初的时候，RNN 是非常流行的的架构， encdoer and deconder 是RNN的流行架构。

将整个输入文本处理成隐藏状态（记忆单元）

![alt text](../../assets/img/notes/LLM/image.png)

这种的限制是，RNN 无法访问使用编码器的早期状态，会导致上下文信息的丢失。


## 3.2 使用注意力机制捕捉数据依赖性

Bahdanau（这位研究员）在 2014 年提出了一种新方法，给这位翻译员（解码器）一项特权：他可以随时回头看原句。

模型不再依赖那个唯一的、被压缩的“死记忆”（隐藏层状态），而是拥有了动态搜索的能力。

仅三年后，研究人员发现RNN架构并不是构建自然语言处理的深度神经网络所必需的，并提出了原始的Transformer架构，自注意力是一种机制，允许输入序列中的每个位置在计算序列表示时考虑同一序列中所有其他位置的相关性或“注意”。

## 3.3 使用自注意力机制关注输入的不同部分

所谓自注意力机制，实际上就是自己关联单个输入序列中的不同位置来计算注
意力权重的能力。

![alt text](../../assets/img/notes/LLM/image-1.png)

1. 字符串转换到词向量
2. 利用这个词向量，进行计算涉及到自己和其他向量，最终得到一个系数，然后这个系数组成了自相关矩阵
3. 运算涉及到点积,向量的点击： 矩阵乘法就是高效版、并行版的点积，什么显卡能加速 AI 训练。
![alt text](../../assets/img/notes/LLM/image-2.png)

4. 归一化注意力分数: 使用softmax最终获得其结果

![alt text](../../assets/img/notes/LLM/image-3.png)

5. 计算最终的上下文向量： 所获取的得分系数就是其权重，然后，线性组合后的上下文向量，请注意，这是很多相同的计算同时进行。

![alt text](../../assets/img/notes/LLM/image-4.png)


## 3.4 实现具有可训练权重的自注意力机制

在上述的机制当中，得分函数的设定是死板. 为了能够不断地演化，加入了可训练的参数。
重要的点，切换维度和特征，无非就是理解 Q K V.

维度变换”本质上就是模型在用不同的视角重组信息，提取它此刻最关心的特征。

这里，以一个例子进行解释 游戏角色属性：

1. 输入（3维）：原本的“生数据：  力量 (Strength)：100 敏捷 (Agility)：50 智力 (Intelligence)：10

2. 战斗系统不需要知道你的“力量”是多少，它只关心你的战斗属性，比如“攻击力”和“闪避率”。

3. 权重矩阵: 攻击力 = $0.8 \times$ 力量 + $0.2 \times$ 敏捷 + $0 \times$ 智力
(解释：力量对攻击力贡献最大，敏捷次之，智力没用)
闪避率 = $0 \times$ 力量 + $0.9 \times$ 敏捷 + $0.1 \times$ 智力
(解释：主要靠敏捷，智力有一点点预判加成)

4. 输出（2维）：提取出的“新特征”

线性变换（Linear Transformation），在深度学习里我们通常叫它投影（Projection）。

除了提取新的特征，另外的目的是将任务进行拆解：

Input ($x$)：原材料。Projection ($W$)：为了什么目的去读？变身 $Q$：带着问题去找人。变身 $K$：挂上牌子等人找。变身 $V$：准备好干货给别人。Dot Product ($Q \cdot K$)：这一对儿关系铁不铁？ (算分数)Softmax：把关系量化成百分比。Weighted Sum ($A \cdot V$)：把关系好的朋友的信息吸收到自己脑子里


### 3.4.1 因果掩码

- 普通自注意力：每一个词都能看到句子里所有的词（包括后面的词）。这对“翻译”任务很有用（因为你已经有了整句话）。

- 因果自注意力 (Causal)：这对“生成”任务是作弊。

使用一个面具挡住向量：

| Word / Position |                       (1) |                       (2) |                       (3) |
| --------------- | ------------------------: | ------------------------: | ------------------------: |
| Your (你的)       | ✅ 看自己 → ✅ *View yourself* |        ❌ 剧透 → ❌ *Spoiler* |        ❌ 剧透 → ❌ *Spoiler* |
| journey (旅程)    | ✅ 看以前 → ✅ *View previous* | ✅ 看自己 → ✅ *View yourself* |        ❌ 剧透 → ❌ *Spoiler* |
| starts (开始)     | ✅ 看以前 → ✅ *View previous* | ✅ 看以前 → ✅ *View previous* | ✅ 看自己 → ✅ *View yourself* |


具体的做法是：在 Softmax 之前动手

1. 右上角全是 1 的掩码
2. 把右上角对应的原始分数 (Scores) 替换成 负无穷大 ($-\infty$)
3. 因为 $e^{-\infty} \approx 0$
4. 那些位置的概率自动变成了 0

### 3.4.2 Dropout layer 

在计算出注意力权重后，随机地把其中一部分变成0.

补偿机制 (Scaling)：

如果你扔掉了一半的人，剩下的人声音就要大一倍，才能保持总音量不变。

## 3.5 将单头注意力扩展到多头注意力

所谓的多头就是 之前只有 一组 查询 ($Q$)、一个键 ($K$) 和一个值 ($V$)的参数，只能代表一种特征，于是，就认为应该有多个特征，意味着有多组参数。

多头的解法：我们雇佣一组专家（比如 4 个或 12 个头），大家同时读这句话，但分工不同：

头 1：专门关注语法（主谓宾匹配）。

头 2：专门关注指代（比如 "it" 指的是谁）。

头 3：专门关注上下文情感（是开心还是生气）。


