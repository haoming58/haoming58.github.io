---
layout: note_with_toc
title: 1. 序列建模基础
description: Basic concepts and principles of sequence modeling
category: Machine Learning
tags: [RNN, Sequence Modeling, Deep Learning, Neural Networks]
permalink: /notes/sequence-modeling-basics/
redirect_from:
  - /notes/RNN序列建模基础/
---

# 1. 序列建模基础

## 1.1 什么是序列模型？

有些数据是“有顺序”的，比如：

- 股票价格每天的变化
- 一个人说话时的语音
- 天气的温度变化

这些数据的**顺序不能打乱**，否则意义就全变了。
 👉 所以我们需要**序列模型**，来理解“过去会怎样影响未来”。

## 1.2 常见的统计方法

### 1.2.1 自回归模型（AR）

 **直观理解**：
 预测未来，靠的是“过去的自己”。

- 比如预测今天的股票价格，我们可以参考前几天的价格。
- 但数据太多会很麻烦，所以只看最近的一段（比如最近 3 天），这就叫**窗口 $\tau$**。

公式写出来：

$$
x_t = P(x_t \mid x_{t-1}, x_{t-2}, \ldots, x_{t-\tau})
$$

📌 **生活类比**
就像你复习考试，只需要看最近几天的复习笔记，不可能把所有学过的都重新背一遍。

### 1.2.2 隐变量自回归模型（Latent AR）

问题来了：
如果历史特别长（比如看 1 年的股价），光靠窗口还是太复杂。

于是我们想了个办法：
 👉 用一个“总结笔记” $h_t$，把过去的内容都总结进去。
以后预测的时候，就直接参考这份总结，而不是看所有历史。

![RNN隐藏状态概念]({{ '/assets/img/notes/rnn/figures/rnn_hidden_state_concept.png' | relative_url }})

公式：

$$
x_t \sim P(x_t \mid h_t), \quad h_t = f(h_{t-1}, x_{t-1})
$$

📌 **生活类比**
就像上课时，你不会把老师说的每一句话都记下来，而是做一份“课堂总结”。以后复习考试时，你看的是总结，而不是完整课堂录音。

### 1.2.3 马尔可夫模型

马尔可夫模型的思想很简单：
 👉 **未来只依赖最近的情况，不依赖更久远的历史。**

- 如果只依赖“上一刻”的状态，这叫“一阶马尔可夫”。
- 比如预测明天天气，只看今天的天气，不看更久之前的。

公式：

$$
P(x_{t+1} \mid x_1,\ldots,x_t) = P(x_{t+1} \mid x_t)
$$

📌 **生活类比**
你决定明天要不要带伞，通常只看今天的天气，不会去管一个月前的天气。

### 1.2.4 因果关系

概率的公式可以随便换顺序，但时间可不是。

 👉 现实生活里，**过去影响未来，但未来不能影响过去**。

- 解释 $P(z_{t+1} \mid z_t)$（未来依赖于现在）是合理的；
- 解释 $P(z_t \mid z_{t+1})$（现在依赖未来）就不符合因果关系。

📌 **生活类比**
你今天是否会下雨，不能由“明天会不会下雨”来决定。

## 1.3 总结

这样讲下来：

- 自回归模型：看过去几步
- 隐变量模型：做总结笔记
- 马尔可夫模型：未来只看最近
- 因果关系：只能“由前推后”

---

## 1.4 代码实践

### 1.4.1 原始数据
在代码实践部分，有 2 块内容：一块是带详细注释的“解释版代码”，另一块是可以直接复制的“干净代码”。本节使用正弦函数叠加高斯噪声生成训练用的时间序列。

**解释版代码：**
```python
%matplotlib inline
import torch
from torch import nn
from d2l import torch as d2l

# 1. 生成时间序列索引
T = 1000
time = torch.arange(1, T + 1, dtype=torch.float32)

# 2. 构造带噪声的正弦信号
x = torch.sin(0.01 * time) + torch.normal(0, 0.2, (T,))

# 3. 可视化
d2l.plot(time, [x], 'time', 'x', xlim=[1, 1000], figsize=(6, 3))
```

**代码说明：**
- `%matplotlib inline` 让 Jupyter 在单元格内直接展示绘图结果。
- `torch.arange(1, T + 1, dtype=torch.float32)` 生成长度为 `T` 的浮点时间索引（左闭右开区间）。
- `torch.normal(0, 0.2, (T,))` 产生标准差为 0.2 的噪声，与正弦信号相加得到 $x = \sin(0.01t) + \varepsilon$。
- `d2l.plot` 接收 `time` 与 `[x]`（注意必须是列表）绘制折线图，`xlim` 与 `figsize` 控制横轴范围和图像尺寸。

**干净代码：**
```python
%matplotlib inline
import torch
from torch import nn
from d2l import torch as d2l

T = 1000  # 总共产生1000个点
time = torch.arange(1, T + 1, dtype=torch.float32)
x = torch.sin(0.01 * time) + torch.normal(0, 0.2, (T,))
d2l.plot(time, [x], 'time', 'x', xlim=[1, 1000], figsize=(6, 3))
```

**关键要点：**
- 序列是离散采样的连续信号；噪声服从均值 0、标准差 0.2 的正态分布。
- `torch.arange` 默认生成 `[1, T+1)`，因此元素个数恰好为 `T`。
- `d2l.plot` 的第二个参数需要列表形式，即使只有一条曲线也要写成 `[x]`，以便统一绘图接口。

![正弦波序列图]({{ '/assets/img/notes/rnn/figures/sequence_sinwave_plot.png' | relative_url }})

### 1.4.2 转化

为了在监督学习框架下训练模型，需要把时间序列切分为“特征－标签”对。窗口大小 `tau` 决定了每个特征包含的历史信息：

$$
X_i = [x_i, x_{i+1}, \dots, x_{i+\tau-1}], \quad Y_i = x_{i+\tau}
$$

**窗口拆分示例（`tau = 5`）**
```python
# 第1个数据对
X1 = [x1, x2, x3, x4, x5]
Y1 = x6

# 第2个数据对
X2 = [x2, x3, x4, x5, x6]
Y2 = x7

# 第3个数据对
X3 = [x3, x4, x5, x6, x7]
Y3 = x8
```

- 最前面的 `tau` 个位置不能作为标签，因为缺少足够的历史数据（例如要预测 `x5` 时需要 `[x0, x1, x2, x3, x4]`）。
- 标签数量与样本数量相等，等于 `序列长度 - tau`：

$$
\text{总样本数} = \text{序列长度} - \tau
$$

### 1.4.3 基本数据处理

将窗口化样本整理成可训练的数据集时，仍然分为“解释版代码”和“干净代码”两套实现。这里依旧只使用前 600 个“特征－标签”对进行训练。

**解释版代码：**
```python
# 1. 定义特征矩阵：行 = 样本数，列 = 窗口长度 tau
features = torch.zeros((T - tau, tau))

# 2. 构造滞后特征：按列填充，保持时间顺序
for i in range(tau):
    features[:, i] = x[i: T - tau + i]

# 3. 构造标签：窗口结束后的下一个时间点，reshape 成列向量
labels = x[tau:].reshape((-1, 1))

# 4. 仅使用前 n_train 个样本参与训练
batch_size, n_train = 16, 600
train_iter = d2l.load_array(
    (features[:n_train], labels[:n_train]),
    batch_size,
    is_train=True
)
```

**补充说明：**
- `features` 的每行对应一个样本，例如 `features = [[x1, x2, x3, x4, x5], [x2, x3, x4, x5, x6], …]`，构成所谓的「滞后特征」(lag features)。
- 若 `tau = 3` 且 `T = 6`，那么：
  - `i = 0` 时 `x[0:3] = [x1, x2, x3] → features[:, 0]`
  - `i = 1` 时 `x[1:4] = [x2, x3, x4] → features[:, 1]`
  - `i = 2` 时 `x[2:5] = [x3, x4, x5] → features[:, 2]`
- 标签 `labels = x[tau:]`，即 `[x_{tau+1}, x_{tau+2}, …]`，并通过 `reshape((-1, 1))` 转换为列向量，`-1` 代表自动推断样本数。
- `d2l.load_array` 生成小批量迭代器，只有前 `n_train` 条样本会参与训练（例如 600 条）。

**干净代码：**
```python
tau = 4
features = torch.zeros((T - tau, tau))
for i in range(tau):
    features[:, i] = x[i: T - tau + i]
labels = x[tau:].reshape((-1, 1))

batch_size, n_train = 16, 600
train_iter = d2l.load_array((features[:n_train], labels[:n_train]),
                            batch_size, is_train=True)
```

### 1.4.4 模型架构

接下来构建一个简单的多层感知机，并给出训练流程。仍然保留注释详尽的“解释版代码”和便于复制的“干净代码”。

**解释版代码：**
```python
# 初始化全连接层权重，保持输入输出方差一致，避免梯度消失/爆炸
def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.xavier_uniform_(m.weight)

# 按顺序堆叠两层线性映射与 ReLU 激活
def get_net():
    net = nn.Sequential(
        nn.Linear(2, 10),
        nn.ReLU(),
        nn.Linear(10, 1)
    )
    net.apply(init_weights)
    return ne

# MSELoss(reduction='none')：保留每个样本的平方误差
loss = nn.MSELoss(reduction='none')

# 训练循环：Adam 优化器 + 梯度清零 + 反向传播
def train(net, train_iter, loss, epochs, lr):
    trainer = torch.optim.Adam(net.parameters(), lr)
    for epoch in range(epochs):
        for X, y in train_iter:
            trainer.zero_grad()        # PyTorch 梯度默认累加，需手动清零
            l = loss(net(X), y)
            l.sum().backward()         # 反向传播计算梯度
            trainer.step()             # 根据梯度更新模型参数
        print(f'epoch {epoch + 1}, '
              f'loss: {d2l.evaluate_loss(net, train_iter, loss):f}')

net = get_net()
train(net, train_iter, loss, 5, 0.01)
```

**干净代码：**
```python
def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.xavier_uniform_(m.weight)

def get_net():
    net = nn.Sequential(nn.Linear(2, 10),
                        nn.ReLU(),
                        nn.Linear(10, 1))
    net.apply(init_weights)
    return ne

loss = nn.MSELoss(reduction='none')

def train(net, train_iter, loss, epochs, lr):
    trainer = torch.optim.Adam(net.parameters(), lr)
    for epoch in range(epochs):
        for X, y in train_iter:
            trainer.zero_grad()
            l = loss(net(X), y)
            l.sum().backward()
            trainer.step()
        print(f'epoch {epoch + 1}, '
              f'loss: {d2l.evaluate_loss(net, train_iter, loss):f}')

net = get_net()
train(net, train_iter, loss, 5, 0.01)
```

![4步预测结果]({{ '/assets/img/notes/rnn/figures/prediction_4step.png' | relative_url }})

### 1.4.5 预测

预测任务可以分为单步预测与多步预测：单步预测每次只预测下一个时间点，多步预测会递归地向前推若干步，误差也会随之累积。

#### 单步预测

**解释版代码：**
```python
# 直接将所有特征送入训练好的模型，得到一步预测结果
onestep_preds = net(features)

# 绘制真实曲线与一步预测曲线
d2l.plot([time, time[tau:]],
         [x.detach().numpy(), onestep_preds.detach().numpy()],
         'time', 'x', legend=['data', '1-step preds'],
         xlim=[1, 1000], figsize=(6, 3))
# 注意：预测序列的时间索引是 time[tau:]，需要与特征矩阵对齐
```

**干净代码：**
```python
onestep_preds = net(features)
d2l.plot([time, time[tau:]],
         [x.detach().numpy(), onestep_preds.detach().numpy()],
         'time', 'x', legend=['data', '1-step preds'],
         xlim=[1, 1000], figsize=(6, 3))
```

![单步vs多步预测对比]({{ '/assets/img/notes/rnn/figures/prediction_1step_vs_multistep.png' | relative_url }})

#### 多步预测

多步预测通常通过递归实现：把模型的预测值再作为下一次输入。这样能够生成任意长度的未来序列，但误差会逐步放大。

**解释版代码：**
```python
# 1. 先复制已有观测，维持前 n_train + tau 个真实数值
multistep_preds = torch.zeros(T)
multistep_preds[: n_train + tau] = x[: n_train + tau]

# 2. 从第 n_train + tau 个时间点开始递归预测
for i in range(n_train + tau, T):
    history = multistep_preds[i - tau:i].reshape((1, -1))
    multistep_preds[i] = net(history)

# 3. 绘制真实曲线、一阶预测、多步预测对比
d2l.plot([time, time[tau:], time[n_train + tau:]],
         [x.detach().numpy(),
          onestep_preds.detach().numpy(),
          multistep_preds[n_train + tau:].detach().numpy()],
         'time', 'x', legend=['data', '1-step preds', 'multistep preds'],
         xlim=[1, 1000], figsize=(6, 3))
# 循环中的 i 依次遍历 604, 605, ..., 999，每一步都依赖前 tau 个历史/预测值
```

**干净代码：**
```python
multistep_preds = torch.zeros(T)
multistep_preds[: n_train + tau] = x[: n_train + tau]
for i in range(n_train + tau, T):
    multistep_preds[i] = net(
        multistep_preds[i - tau:i].reshape((1, -1)))

d2l.plot([time, time[tau:], time[n_train + tau:]],
         [x.detach().numpy(), onestep_preds.detach().numpy(),
          multistep_preds[n_train + tau:].detach().numpy()],
         'time', 'x', legend=['data', '1-step preds', 'multistep preds'],
         xlim=[1, 1000], figsize=(6, 3))
```

![K步预测对比]({{ '/assets/img/notes/rnn/figures/prediction_k_steps.png' | relative_url }})

**思考：多步预测与样本数量**

| 历史1 | 历史2 | 1-step | 2-step | 3-step |
| ----- | ----- | ------ | ------ | ------ |
| t1    | t2    | t3     | t4     | t5     |
| t2    | t3    | t4     | t5     | t6     |
| t3    | t4    | t5     | t6     | t7     |

- **1-step 预测**：使用 `[t1, t2]` 预测 `t3`，再用 `[t2, t3]` 预测 `t4`，以此类推。
- **2-step 预测**：先预测 `t3`，再预测 `t4`，每一步都依赖于前一次的真实值或预测值。
- **3-step 预测**：尝试预测 `t5、t6`，若序列长度只有 6，则无法继续得到 `t7` 的真实标签用于验证。

当序列长度为 `T`、窗口为 `tau`、最远预测步数为 `max_steps` 时，可采样的窗口数量为：

$$
N = T - \tau - \text{max\_steps} + 1
$$

**多步预测特征构造与可视化（解释版代码）：**
```python
# 生成用于 K 步预测的特征矩阵
features = torch.zeros((T - tau - max_steps + 1, tau + max_steps))

# 1. 历史部分（前 tau 列）
for i in range(tau):
    features[:, i] = x[i: i + T - tau - max_steps + 1]

# 2. 递归预测部分（后 max_steps 列）
for i in range(tau, tau + max_steps):
    features[:, i] = net(features[:, i - tau:i]).reshape(-1)

# 3. 绘制不同预测步长的对比曲线
steps = (1, 4, 16, 64)
d2l.plot(
    [time[tau + i - 1: T - max_steps + i] for i in steps],
    [features[:, tau + i - 1].detach().numpy() for i in steps],
    'time', 'x', legend=[f'{i}-step preds' for i in steps],
    xlim=[5, 1000], figsize=(6, 3)
)
# 前 tau 列是历史观测，后 max_steps 列是递归预测
# 样本数受 T、tau、max_steps 同时限制
# 通过不同步长曲线可以观察误差随预测距离的累积情况
```